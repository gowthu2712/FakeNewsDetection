{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import codecs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLIT = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_lines(file, label):\n",
    "    data = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            #Legitimate news label is 0\n",
    "            data.append({\"text\":line, \"label\": label})\n",
    "    return pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_CSV(file, delimit, label):\n",
    "    df = pd.read_csv(file, delimiter=delimit, encoding=\"utf-8\")\n",
    "    #Fake News label is 1\n",
    "    df['label'] = label\n",
    "    return df[[\"text\", \"label\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    SPLIT = 0.20\n",
    "    def __init__(self, fake_news_file, true_news_file, true_news_file2, fake_news_file2):\n",
    "        self.data = pd.concat([extract_CSV(fake_news_file, ',', 1), extract_lines(true_news_file, 0), \n",
    "                               extract_lines(true_news_file2, 0), extract_lines(fake_news_file2, 1)])\n",
    "        \n",
    "        self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "        self.training_data = []\n",
    "        self.training_label = []\n",
    "        self.test_data = []\n",
    "        self.test_label = []\n",
    "    \n",
    "    def split_dataset(self):\n",
    "        \"\"\"\n",
    "        Remove all irregularities in the data set and split to training and test data\n",
    "        \"\"\"\n",
    "        print \"length = \", len(self.data)\n",
    "        for i in xrange(int(len(self.data)*DataSet.SPLIT)+1):\n",
    "            # To remove all the float type data which gives no information on textual features\n",
    "            if type(self.data['text'].iloc[i]) != type(0.5):\n",
    "                text = ''.join(k for k in self.data['text'].iloc[i] if not k.isdigit() and type(k) != type(0.5))\n",
    "                if len(text) > 10:\n",
    "                    self.test_data.append(text)\n",
    "                    self.test_label.append(self.data['label'].iloc[i])\n",
    "        \n",
    "        for i in xrange(int(len(self.data)*DataSet.SPLIT)+1, len(self.data)):\n",
    "            # To remove all the float type data which gives no information on textual features\n",
    "            if type(self.data['text'].iloc[i]) != type(0.5):\n",
    "                text = ''.join(k for k in self.data['text'].iloc[i] if not k.isdigit() and type(k) != type(0.5))\n",
    "                if len(text) > 10: \n",
    "                    self.training_data.append(text)\n",
    "                    self.training_label.append(self.data['label'].iloc[i])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(fake_news_file, true_news_file, true_news_file2, fake_news_file2):\n",
    "    #data = pd.concat([extract_CSV(fake_news_file, ',', 1), extract_lines(true_news_file, 0), \n",
    "    #                           extract_lines(true_news_file2, 0), extract_lines(fake_news_file2, 1)])\n",
    "    data = pd.concat([extract_lines(true_news_file2, 0), extract_lines(fake_news_file2, 1)])\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    training_data = []\n",
    "    training_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    \n",
    "    \n",
    "    for i in xrange(int(len(data)*SPLIT)+1):\n",
    "        # To remove all the float type data which gives no information on textual features\n",
    "        if type(data['text'].iloc[i]) != type(0.5):\n",
    "            text = ''.join(k for k in data['text'].iloc[i] if not k.isdigit() and type(k) != type(0.5))\n",
    "            if len(text) > 10:\n",
    "                test_data.append(text)\n",
    "                test_label.append(data['label'].iloc[i])\n",
    "        \n",
    "    for i in xrange(int(len(data)*SPLIT)+1, len(data)):\n",
    "        # To remove all the float type data which gives no information on textual features\n",
    "        if type(data['text'].iloc[i]) != type(0.5):\n",
    "            text = ''.join(k for k in data['text'].iloc[i] if not k.isdigit() and type(k) != type(0.5))\n",
    "            if len(text) > 10: \n",
    "                training_data.append(text)\n",
    "                training_label.append(data['label'].iloc[i])\n",
    "    \n",
    "    return (training_data, training_label, test_data, test_label)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_SVM(count_vect, training_data, training_label):\n",
    "    X_train = count_vect.fit_transform(training_data)\n",
    "    svm_instance = svm.SVC(gamma=0.001, C=100)\n",
    "    svm_instance.fit(X_train, training_label) \n",
    "    return svm_instance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_SVM(count_vect, clf, test_data):\n",
    "    X_test = count_vect.transform(test_data) \n",
    "    predict_test = clf.predict(X_test)\n",
    "    return predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predict, test_label):\n",
    "    accuracy = 0\n",
    "    for i in xrange(len(predict)):\n",
    "        if predict[i] == test_label[i]:\n",
    "            accuracy += 1\n",
    "    return accuracy*1.0/len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(predict, test_label):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    \n",
    "    for i in xrange(len(predict)):\n",
    "        if predict[i] == test_label[i] and predict[i] == 1:\n",
    "            TP += 1\n",
    "        elif predict[i] == test_label[i] and predict[i] == 0:\n",
    "            TN += 1\n",
    "    TPR = TP*1.0/(TP+TN)\n",
    "    TNR = TN*1.0/(TP+TN)\n",
    "    \n",
    "    class_accuracy = (TP+TN)*1.0/(len(predict))\n",
    "    return (TPR, TNR, class_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, dataset):\n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.dataset = dataset\n",
    "        self.count_vect = CountVectorizer(min_df=1)\n",
    "        \n",
    "    def train(self):   \n",
    "        self.X_train = self.count_vect.fit_transform(self.dataset.training_data)\n",
    "        clf = svm.SVC(gamma=0.001, C=100)\n",
    "        clf.fit(self.X_train, self.dataset.training_label) \n",
    "    \n",
    "    def test(self):\n",
    "        self.X_test = count_vect.transform(self.dataset.test_data)\n",
    "        #self.X_test = count_vect.transform([\"Bala is a sore loser who sucks at playing Flappy Bird but still better than Kumaran\"]) \n",
    "        predict_test = clf.predict(self.X_test)\n",
    "        return predict_test\n",
    "\n",
    "    def accuracy(self, predict):\n",
    "        accuracy = 0\n",
    "        for i in xrange(len(predict)):\n",
    "            if predict[i] == self.dataset.test_label[i]:\n",
    "                accuracy += 1\n",
    "        return accuracy*1.0/len(predict)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    FAKE_NEWS_FILE = \"../data/fake.csv\"\n",
    "    TRUE_NEWS_FILE = \"../data/trueCorpora.txt\"\n",
    "    TRUE_NEWS_FILE2 = \"../data/real-news\"\n",
    "    FAKE_NEWS_FILE2 = \"../data/fake-news\"\n",
    "    \n",
    "    (training_data, training_label, test_data, test_label) = get_dataset(FAKE_NEWS_FILE, TRUE_NEWS_FILE, \n",
    "                                                                         TRUE_NEWS_FILE2, FAKE_NEWS_FILE2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #Bag of words and SVM\n",
    "    count_vect = CountVectorizer(min_df=1)\n",
    "    clf = train_SVM(count_vect, training_data, training_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label: Count_0 =  9206  and count_1 =  10879\n",
      "Test label: Count_0 =  2319  and count_1 =  2707\n"
     ]
    }
   ],
   "source": [
    "    count_1 = 0\n",
    "    count_0 = 0\n",
    "    \n",
    "    for i in training_label:\n",
    "        if i == 1:\n",
    "            count_1 += 1\n",
    "        else:\n",
    "            count_0 += 1\n",
    "    print \"Training label: Count_0 = \", count_0, \" and count_1 = \", count_1\n",
    "    \n",
    "    count_1 = 0\n",
    "    count_0 = 0\n",
    "    \n",
    "    for i in test_label:\n",
    "        if i == 1:\n",
    "            count_1 += 1\n",
    "        else:\n",
    "            count_0 += 1\n",
    "    print \"Test label: Count_0 = \", count_0, \" and count_1 = \", count_1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "    prediction = test_SVM(count_vect, clf, [\"\"])\n",
    "    print prediction\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    count_1 = 0\n",
    "    count_0 = 0\n",
    "    \n",
    "    for i in prediction:\n",
    "        if i == 1:\n",
    "            count_1 += 1\n",
    "        else:\n",
    "            count_0 += 1\n",
    "    \n",
    "    print \"Prediction label: Count_0 = \", count_0, \" and count_1 = \", count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR =  0.553359683794  TNR =  0.446640316206  Classification accuracy =  0.906088340629\n"
     ]
    }
   ],
   "source": [
    "    TPR, TNR, class_accuracy = get_classification_accuracy(test_label, prediction)\n",
    "    print \"TPR = \", TPR, \" TNR = \", TNR, \" Classification accuracy = \", class_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
